{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64286b88-91ad-45b3-812c-708f9b599628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiledb\n",
      "  Downloading tiledb-0.36.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy>=1.25 in /ibex/user/zharkyy/conda-environments/pytorch/lib/python3.12/site-packages (from tiledb) (1.26.4)\n",
      "Requirement already satisfied: packaging in /ibex/user/zharkyy/conda-environments/pytorch/lib/python3.12/site-packages (from tiledb) (25.0)\n",
      "Downloading tiledb-0.36.0-cp312-cp312-manylinux_2_28_x86_64.whl (18.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m6m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiledb\n",
      "Successfully installed tiledb-0.36.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiledb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697194e7-f06a-4ba3-bc71-81ac3e02c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysz\n",
      "  Downloading pysz-1.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /ibex/user/zharkyy/conda-environments/pytorch/lib/python3.12/site-packages (from pysz) (1.26.4)\n",
      "Downloading pysz-1.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pysz\n",
      "Successfully installed pysz-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pysz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9699ab-d22d-4cff-bfaf-716e8f4c16d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.01)...\n",
      "Internal SZ Ratio: 39.77\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 0.39 GB\n",
      "Final Compression Ratio (rho): 39.7725\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.8495941162109375\n",
      "Max Relative Error (calc): 0.009999874047935009\n",
      "Target Epsilon: 0.01\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2 \n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    \n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68757bef-e0c8-43e7-bd2d-6a8579bd9a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.001)...\n",
      "Internal SZ Ratio: 8.73\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 1.77 GB\n",
      "Final Compression Ratio (rho): 8.7306\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.0849456787109375\n",
      "Max Relative Error (calc): 0.0009998257737606764\n",
      "Target Epsilon: 0.001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-3\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    \n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0839fc-9656-4538-bcf7-bd810ead5f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.0001)...\n",
      "Internal SZ Ratio: 4.51\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 3.44 GB\n",
      "Final Compression Ratio (rho): 4.5053\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.00848388671875\n",
      "Max Relative Error (calc): 9.985685755964369e-05\n",
      "Target Epsilon: 0.0001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-4\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    \n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int64))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abb2b7-3b28-4dc0-9c11-2016d650f80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea22c22-e8cf-4b4e-94ec-dfcc0855057b",
   "metadata": {},
   "source": [
    "\n",
    "# Interpolation only algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7190f3e7-cc8b-4fed-9e1a-41e9f6cca6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.01)...\n",
      "Internal SZ Ratio: 36.12\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 0.43 GB\n",
      "Final Compression Ratio (rho): 36.1225\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.8495941162109375\n",
      "Max Relative Error (calc): 0.009999874047935009\n",
      "Target Epsilon: 0.01\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.INTERP        # Interpolation only\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6fc4bb-6fbe-48d2-86a4-2e2d99956977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.001)...\n",
      "Internal SZ Ratio: 8.61\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 1.80 GB\n",
      "Final Compression Ratio (rho): 8.6148\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.0849456787109375\n",
      "Max Relative Error (calc): 0.0009998257737606764\n",
      "Target Epsilon: 0.001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-3\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.INTERP        # Interpolation only\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23bf9d9-bc2c-4435-a3a3-dbf62e7c6588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.0001)...\n",
      "Internal SZ Ratio: 4.48\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 3.46 GB\n",
      "Final Compression Ratio (rho): 4.4792\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.00848388671875\n",
      "Max Relative Error (calc): 9.985685755964369e-05\n",
      "Target Epsilon: 0.0001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-4\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.INTERP        # Interpolation only\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int64))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c07f1-5507-4fce-904e-d6ec61ff128c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Lorenzo/regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c28a58-c978-4c92-b990-00e281a61f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.01)...\n",
      "Internal SZ Ratio: 27.31\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 0.57 GB\n",
      "Final Compression Ratio (rho): 27.3130\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.8495941162109375\n",
      "Max Relative Error (calc): 0.009999874047935009\n",
      "Target Epsilon: 0.01\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.LORENZO_REG   # Lorenzo/regression\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e475d119-1b40-4d0a-a9a8-f82882120e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.001)...\n",
      "Internal SZ Ratio: 11.17\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 1.39 GB\n",
      "Final Compression Ratio (rho): 11.1724\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.0849456787109375\n",
      "Max Relative Error (calc): 0.0009998257737606764\n",
      "Target Epsilon: 0.001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-3\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.LORENZO_REG   # Lorenzo/regression\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6c0c67-95a5-4d2f-bf3d-d266f1e7a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.0001)...\n",
      "Internal SZ Ratio: 5.58\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.48 GB\n",
      "Size of Array G (disk): 2.77 GB\n",
      "Final Compression Ratio (rho): 5.5819\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.00848388671875\n",
      "Max Relative Error (calc): 9.985685755964369e-05\n",
      "Target Epsilon: 0.0001\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-4\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=1, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=855, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=1215, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    config.cmprAlgo = szAlgorithm.LORENZO_REG   # Lorenzo/regression\n",
    "\n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int64))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6cc7e3-b8dc-473b-890a-c9540aa0c9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Redsea_t2_4k_gan.dat...\n",
      "Data Range: 84.96047973632812 (Min: 225.58950805664062, Max: 310.54998779296875)\n",
      "Storing original data D in TileDB...\n",
      "Compressing with SZ3 (Relative Error = 0.01)...\n",
      "Internal SZ Ratio: 39.77\n",
      "Storing compressed data G in TileDB...\n",
      "------------------------------\n",
      "Size of Array D (disk): 15.71 GB\n",
      "Size of Array G (disk): 0.39 GB\n",
      "Final Compression Ratio (rho): 40.3494\n",
      "------------------------------\n",
      "Verifying Decompression and Error Bounds...\n",
      "Max Absolute Error: 0.8495941162109375\n",
      "Max Relative Error (calc): 0.009999874047935009\n",
      "Target Epsilon: 0.01\n",
      "SUCCESS: Error bound satisfied Eq. 2!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\" \n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2 \n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {INPUT_FILE} not found. Please download the dataset[cite: 90].\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    print(f\"Data Range: {v_range} (Min: {d_min}, Max: {d_max})\")\n",
    "\n",
    "    print(\"Storing original data D in TileDB...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=10, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=17, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=81, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(domain=dom_d, sparse=False, attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)])\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "\n",
    "    print(f\"Compressing with SZ3 (Relative Error = {EPSILON})...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON \n",
    "    \n",
    "    compressed_bytes, ratio_sz_internal = sz.compress(data_d, config)\n",
    "    \n",
    "    print(f\"Internal SZ Ratio: {ratio_sz_internal:.2f}\")\n",
    "\n",
    "    print(\"Storing compressed data G in TileDB...\")\n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "\n",
    "    comp_size = compressed_bytes.size\n",
    "    dom_g = tiledb.Domain(tiledb.Dim(name=\"index\", domain=(0, comp_size-1), tile=comp_size, dtype=np.int32))\n",
    "    schema_g = tiledb.ArraySchema(domain=dom_g, sparse=False, attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)])\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = compressed_bytes\n",
    "\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    \n",
    "    rho = size_D_folder / size_G_folder\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Size of Array D (disk): {size_D_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Size of Array G (disk): {size_G_folder / (1024**3):.2f} GB\")\n",
    "    print(f\"Final Compression Ratio (rho): {rho:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Verifying Decompression and Error Bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        read_bytes = A[:]['bytes']\n",
    "    \n",
    "    decompressed_data, dec_config = sz.decompress(read_bytes, DTYPE,  SHAPE)\n",
    "    \n",
    "    diff = np.abs(data_d - decompressed_data)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    \n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print(f\"Max Absolute Error: {max_pointwise_diff}\")\n",
    "    print(f\"Max Relative Error (calc): {actual_max_rel_error}\")\n",
    "    print(f\"Target Epsilon: {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9: # small buffer for float precision\n",
    "        print(\"SUCCESS: Error bound satisfied Eq. 2!\")\n",
    "    else:\n",
    "        print(\"WARNING: Error bound NOT satisfied.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f871d6-e7be-49f9-8211-6248dbfabc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac203d-3716-4edc-b700-6dc790a3d590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28aeb63f-4bb7-4fd0-9021-4199a59c5094",
   "metadata": {},
   "source": [
    "**EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8320204-fde5-4caa-9fc8-b4a4c573cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPRESSION TEST WITHOUT TileDB\n",
      "======================================================================\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   📊 Size in memory: 15.48 GB\n",
      "   📈 Data range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "🗜️  Step 2: Compressing with SZ3...\n",
      "   ✅ Compression complete!\n",
      "   📊 SZ3 internal ratio: 39.77×\n",
      "\n",
      "💾 Step 3: Saving compressed data...\n",
      "   ✅ Saved to: compressed_data.dat\n",
      "   📊 Compressed file size: 398.55 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "OUTPUT_COMPRESSED = \"compressed_data.dat\"\n",
    "OUTPUT_DECOMPRESSED = \"decompressed_data.dat\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "def get_file_size(filename):\n",
    "    \"\"\"Get file size in bytes\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        return os.path.getsize(filename)\n",
    "    return 0\n",
    "\n",
    "def format_size(size_bytes):\n",
    "    \"\"\"Format bytes to human readable\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if size_bytes < 1024.0:\n",
    "            return f\"{size_bytes:.2f} {unit}\"\n",
    "        size_bytes /= 1024.0\n",
    "    return f\"{size_bytes:.2f} TB\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPRESSION TEST WITHOUT TileDB\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Step 1: Load original data\n",
    "print(\"📂 Step 1: Loading original data...\")\n",
    "try:\n",
    "    data_original = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "    exit(1)\n",
    "\n",
    "original_size = data_original.nbytes\n",
    "print(f\"   📊 Size in memory: {format_size(original_size)}\")\n",
    "\n",
    "# Calculate data range\n",
    "d_max = data_original.max()\n",
    "d_min = data_original.min()\n",
    "v_range = d_max - d_min\n",
    "print(f\"   📈 Data range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "print()\n",
    "\n",
    "# Step 2: Compress with SZ3\n",
    "print(\"🗜️  Step 2: Compressing with SZ3...\")\n",
    "config = szConfig()\n",
    "config.errorBoundMode = szErrorBoundMode.REL\n",
    "config.relErrorBound = EPSILON\n",
    "\n",
    "compressed_bytes, sz_ratio = sz.compress(data_original, config)\n",
    "print(f\"   ✅ Compression complete!\")\n",
    "print(f\"   📊 SZ3 internal ratio: {sz_ratio:.2f}×\")\n",
    "print()\n",
    "\n",
    "# Step 3: Save compressed data to file\n",
    "print(\"💾 Step 3: Saving compressed data...\")\n",
    "compressed_bytes.tofile(OUTPUT_COMPRESSED)\n",
    "compressed_size = get_file_size(OUTPUT_COMPRESSED)\n",
    "print(f\"   ✅ Saved to: {OUTPUT_COMPRESSED}\")\n",
    "print(f\"   📊 Compressed file size: {format_size(compressed_size)}\")\n",
    "print()\n",
    "\n",
    "# # Step 4: Calculate compression ratio\n",
    "# print(\"📊 Step 4: Calculating compression ratio...\")\n",
    "# compression_ratio = original_size / compressed_size\n",
    "# print(f\"   Original size:    {format_size(original_size)}\")\n",
    "# print(f\"   Compressed size:  {format_size(compressed_size)}\")\n",
    "# print(f\"   🎯 Compression ratio: {compression_ratio:.2f}×\")\n",
    "# print(f\"   💾 Space saved: {((original_size - compressed_size) / original_size * 100):.1f}%\")\n",
    "# print()\n",
    "\n",
    "# # Step 5: Decompress and verify\n",
    "# print(\"🔓 Step 5: Decompressing and verifying...\")\n",
    "# compressed_read = np.fromfile(OUTPUT_COMPRESSED, dtype=np.uint8)\n",
    "# data_decompressed, _ = sz.decompress(compressed_read, DTYPE, SHAPE)\n",
    "\n",
    "# # Save decompressed for inspection\n",
    "# data_decompressed.tofile(OUTPUT_DECOMPRESSED)\n",
    "# decompressed_size = get_file_size(OUTPUT_DECOMPRESSED)\n",
    "# print(f\"   ✅ Decompressed successfully\")\n",
    "# print(f\"   📊 Decompressed size: {format_size(decompressed_size)}\")\n",
    "# print()\n",
    "\n",
    "# # Step 6: Verify error bounds\n",
    "# print(\"🔍 Step 6: Verifying error bounds...\")\n",
    "# diff = np.abs(data_original - data_decompressed)\n",
    "# max_abs_error = diff.max()\n",
    "# max_rel_error = max_abs_error / v_range\n",
    "\n",
    "# print(f\"   Max absolute error: {max_abs_error:.6f}\")\n",
    "# print(f\"   Max relative error: {max_rel_error:.6f}\")\n",
    "# print(f\"   Target epsilon:     {EPSILON}\")\n",
    "\n",
    "# if max_rel_error <= EPSILON + 1e-9:\n",
    "#     print(f\"   ✅ SUCCESS: Error bound satisfied!\")\n",
    "# else:\n",
    "#     print(f\"   ❌ FAILED: Error bound exceeded!\")\n",
    "# print()\n",
    "\n",
    "# # Step 7: Comparison summary\n",
    "# print(\"=\" * 70)\n",
    "# print(\"📊 FINAL SUMMARY (NO TileDB)\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"Original file:      {format_size(original_size):>15}\")\n",
    "# print(f\"Compressed file:    {format_size(compressed_size):>15}\")\n",
    "# print(f\"Compression ratio:  {compression_ratio:>14.2f}×\")\n",
    "# print(f\"Space saved:        {((original_size - compressed_size) / original_size * 100):>13.1f}%\")\n",
    "# print(\"=\" * 70)\n",
    "# print()\n",
    "\n",
    "# # Step 8: What if we used TileDB?\n",
    "# print(\"🤔 What happens with TileDB?\")\n",
    "# print(\"-\" * 70)\n",
    "# print(\"TileDB adds:\")\n",
    "# print(\"  • Schema files (~10-20 MB)\")\n",
    "# print(\"  • Metadata for each tile (~10-50 KB per tile)\")\n",
    "# print(\"  • Fragment info files (~5-10 MB)\")\n",
    "# print(\"  • Directory structure overhead\")\n",
    "# print()\n",
    "# print(\"Estimated TileDB overhead:\")\n",
    "\n",
    "# # Rough estimates\n",
    "# tile_count_d = 4000  # For arrayD with tile=(1,855,1215)\n",
    "# tile_count_g = 1     # For arrayG with tile=comp_size\n",
    "\n",
    "# overhead_d = 20 * 1024**2 + tile_count_d * 10 * 1024  # Schema + per-tile metadata\n",
    "# overhead_g = 20 * 1024**2 + tile_count_g * 10 * 1024\n",
    "\n",
    "# total_with_tiledb = original_size + overhead_d + compressed_size + overhead_g\n",
    "# ratio_with_tiledb = original_size / (compressed_size + overhead_g)\n",
    "\n",
    "# print(f\"  arrayD overhead:    ~{format_size(overhead_d)}\")\n",
    "# print(f\"  arrayG overhead:    ~{format_size(overhead_g)}\")\n",
    "# print(f\"  Total overhead:     ~{format_size(overhead_d + overhead_g)}\")\n",
    "# print()\n",
    "# print(f\"Compression ratio with TileDB: ~{ratio_with_tiledb:.2f}×\")\n",
    "# print(f\"Ratio WITHOUT TileDB:           {compression_ratio:.2f}×\")\n",
    "# print(f\"Difference:                     {compression_ratio - ratio_with_tiledb:.2f}×\")\n",
    "# print(\"=\" * 70)\n",
    "# print()\n",
    "\n",
    "# # Cleanup info\n",
    "# print(\"📁 Files created:\")\n",
    "# print(f\"  • {OUTPUT_COMPRESSED} ({format_size(compressed_size)})\")\n",
    "# print(f\"  • {OUTPUT_DECOMPRESSED} ({format_size(decompressed_size)})\")\n",
    "# print()\n",
    "# print(\"✨ Test complete! You can delete these files when done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31dad42-3322-40f9-8af2-db678af4c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         4000 × 1 × 1215\n",
      "   Tiles per dim:     1 × 855 × 1\n",
      "   Total tiles:       855\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 855 tiles...\n",
      "           1/855 tiles (  0.1%) - Compressed:     1.17 MB\n",
      "          85/855 tiles (  9.9%) - Compressed:    95.26 MB\n",
      "         170/855 tiles ( 19.9%) - Compressed:   194.68 MB\n",
      "         255/855 tiles ( 29.8%) - Compressed:   302.96 MB\n",
      "         340/855 tiles ( 39.8%) - Compressed:   413.43 MB\n",
      "         425/855 tiles ( 49.7%) - Compressed:   534.71 MB\n",
      "         510/855 tiles ( 59.6%) - Compressed:   666.12 MB\n",
      "         595/855 tiles ( 69.6%) - Compressed:   806.70 MB\n",
      "         680/855 tiles ( 79.5%) - Compressed:   956.12 MB\n",
      "         765/855 tiles ( 89.5%) - Compressed:  1073.19 MB\n",
      "         850/855 tiles ( 99.4%) - Compressed:  1181.55 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 1188.45 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (855 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           1.16 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.01 MB  (tile metadata)\n",
      "Total compression size:          1.16 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       13.3376×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 855 tiles...\n",
      "           1/855 tiles (  0.1%)\n",
      "          85/855 tiles (  9.9%)\n",
      "         170/855 tiles ( 19.9%)\n",
      "         255/855 tiles ( 29.8%)\n",
      "         340/855 tiles ( 39.8%)\n",
      "         425/855 tiles ( 49.7%)\n",
      "         510/855 tiles ( 59.6%)\n",
      "         595/855 tiles ( 69.6%)\n",
      "         680/855 tiles ( 79.5%)\n",
      "         765/855 tiles ( 89.5%)\n",
      "         850/855 tiles ( 99.4%)\n",
      "\n",
      "Max Absolute Error:   0.69177246\n",
      "Max Relative Error:   0.00814229\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    4000 × 1 × 1215\n",
      "Total tiles:           855\n",
      "Compression ratio ρ:   13.3376×\n",
      "Space saved:           92.5%\n",
      "Error bound:           0.00814229 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 4000   # Full time dimension\n",
    "TILE_X = 1      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c2440d-3cc9-4b16-aff9-3fadb5dbd9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         1 × 855 × 1215\n",
      "   Tiles per dim:     4000 × 1 × 1\n",
      "   Total tiles:       4000\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%) - Compressed:     0.10 MB\n",
      "         400/4000 tiles ( 10.0%) - Compressed:    39.14 MB\n",
      "         800/4000 tiles ( 20.0%) - Compressed:    78.26 MB\n",
      "        1200/4000 tiles ( 30.0%) - Compressed:   117.33 MB\n",
      "        1600/4000 tiles ( 40.0%) - Compressed:   156.44 MB\n",
      "        2000/4000 tiles ( 50.0%) - Compressed:   195.55 MB\n",
      "        2400/4000 tiles ( 60.0%) - Compressed:   234.50 MB\n",
      "        2800/4000 tiles ( 70.0%) - Compressed:   273.50 MB\n",
      "        3200/4000 tiles ( 80.0%) - Compressed:   312.59 MB\n",
      "        3600/4000 tiles ( 90.0%) - Compressed:   351.69 MB\n",
      "        4000/4000 tiles (100.0%) - Compressed:   390.67 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 390.67 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (4000 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.38 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.03 MB  (tile metadata)\n",
      "Total compression size:          0.38 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       40.5712×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%)\n",
      "         400/4000 tiles ( 10.0%)\n",
      "         800/4000 tiles ( 20.0%)\n",
      "        1200/4000 tiles ( 30.0%)\n",
      "        1600/4000 tiles ( 40.0%)\n",
      "        2000/4000 tiles ( 50.0%)\n",
      "        2400/4000 tiles ( 60.0%)\n",
      "        2800/4000 tiles ( 70.0%)\n",
      "        3200/4000 tiles ( 80.0%)\n",
      "        3600/4000 tiles ( 90.0%)\n",
      "        4000/4000 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.82327271\n",
      "Max Relative Error:   0.00969007\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    1 × 855 × 1215\n",
      "Total tiles:           4000\n",
      "Compression ratio ρ:   40.5712×\n",
      "Space saved:           97.5%\n",
      "Error bound:           0.00969007 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 1   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f067629-b036-48c9-b4cf-d015841fc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         100 × 100 × 100\n",
      "   Tiles per dim:     40 × 9 × 13\n",
      "   Total tiles:       4680\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 4680 tiles...\n",
      "           1/4680 tiles (  0.0%) - Compressed:     0.27 MB\n",
      "         468/4680 tiles ( 10.0%) - Compressed:   106.60 MB\n",
      "         936/4680 tiles ( 20.0%) - Compressed:   213.58 MB\n",
      "        1404/4680 tiles ( 30.0%) - Compressed:   320.39 MB\n",
      "        1872/4680 tiles ( 40.0%) - Compressed:   425.82 MB\n",
      "        2340/4680 tiles ( 50.0%) - Compressed:   533.08 MB\n",
      "        2808/4680 tiles ( 60.0%) - Compressed:   639.48 MB\n",
      "        3276/4680 tiles ( 70.0%) - Compressed:   746.32 MB\n",
      "        3744/4680 tiles ( 80.0%) - Compressed:   853.21 MB\n",
      "        4212/4680 tiles ( 90.0%) - Compressed:   959.86 MB\n",
      "        4680/4680 tiles (100.0%) - Compressed:  1066.58 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 1066.58 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (4680 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          17.44 GB\n",
      "Size of arrayG (disk):           1.04 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.04 MB  (tile metadata)\n",
      "Total compression size:          1.04 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       16.7378×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 4680 tiles...\n",
      "           1/4680 tiles (  0.0%)\n",
      "         468/4680 tiles ( 10.0%)\n",
      "         936/4680 tiles ( 20.0%)\n",
      "        1404/4680 tiles ( 30.0%)\n",
      "        1872/4680 tiles ( 40.0%)\n",
      "        2340/4680 tiles ( 50.0%)\n",
      "        2808/4680 tiles ( 60.0%)\n",
      "        3276/4680 tiles ( 70.0%)\n",
      "        3744/4680 tiles ( 80.0%)\n",
      "        4212/4680 tiles ( 90.0%)\n",
      "        4680/4680 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.63768005\n",
      "Max Relative Error:   0.00750561\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    100 × 100 × 100\n",
      "Total tiles:           4680\n",
      "Compression ratio ρ:   16.7378×\n",
      "Space saved:           94.0%\n",
      "Error bound:           0.00750561 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 100   # Full time dimension\n",
    "TILE_X = 100      # One X position\n",
    "TILE_Y = 100   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d649c8-88f7-4c9c-86b5-ba56a7c1af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         400 × 400 × 400\n",
      "   Tiles per dim:     10 × 3 × 4\n",
      "   Total tiles:       120\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "Size of arrayD (disk):          28.62 GB\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 120 tiles...\n",
      "           1/120 tiles (  0.8%) - Compressed:    12.43 MB\n",
      "          12/120 tiles ( 10.0%) - Compressed:    66.69 MB\n",
      "          24/120 tiles ( 20.0%) - Compressed:   132.25 MB\n",
      "          36/120 tiles ( 30.0%) - Compressed:   199.43 MB\n",
      "          48/120 tiles ( 40.0%) - Compressed:   266.15 MB\n",
      "          60/120 tiles ( 50.0%) - Compressed:   332.32 MB\n",
      "          72/120 tiles ( 60.0%) - Compressed:   398.93 MB\n",
      "          84/120 tiles ( 70.0%) - Compressed:   465.36 MB\n",
      "          96/120 tiles ( 80.0%) - Compressed:   531.77 MB\n",
      "         108/120 tiles ( 90.0%) - Compressed:   598.54 MB\n",
      "         120/120 tiles (100.0%) - Compressed:   663.71 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 663.71 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (120 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          28.62 GB\n",
      "Size of arrayG (disk):           0.65 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.00 MB  (tile metadata)\n",
      "Total compression size:          0.65 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       44.1407×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 120 tiles...\n",
      "           1/120 tiles (  0.8%)\n",
      "          12/120 tiles ( 10.0%)\n",
      "          24/120 tiles ( 20.0%)\n",
      "          36/120 tiles ( 30.0%)\n",
      "          48/120 tiles ( 40.0%)\n",
      "          60/120 tiles ( 50.0%)\n",
      "          72/120 tiles ( 60.0%)\n",
      "          84/120 tiles ( 70.0%)\n",
      "          96/120 tiles ( 80.0%)\n",
      "         108/120 tiles ( 90.0%)\n",
      "         120/120 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.76150513\n",
      "Max Relative Error:   0.00896305\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    400 × 400 × 400\n",
      "Total tiles:           120\n",
      "Compression ratio ρ:   44.1407×\n",
      "Space saved:           97.7%\n",
      "Error bound:           0.00896305 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 400   # Full time dimension\n",
    "TILE_X = 400      # One X position\n",
    "TILE_Y = 400   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5f2e0d-271f-4760-9fe0-a07590b5bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         400 × 855 × 1215\n",
      "   Tiles per dim:     10 × 1 × 1\n",
      "   Total tiles:       10\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 10 tiles...\n",
      "           1/10 tiles ( 10.0%) - Compressed:    40.70 MB\n",
      "           2/10 tiles ( 20.0%) - Compressed:    81.64 MB\n",
      "           3/10 tiles ( 30.0%) - Compressed:   122.28 MB\n",
      "           4/10 tiles ( 40.0%) - Compressed:   163.29 MB\n",
      "           5/10 tiles ( 50.0%) - Compressed:   204.15 MB\n",
      "           6/10 tiles ( 60.0%) - Compressed:   244.88 MB\n",
      "           7/10 tiles ( 70.0%) - Compressed:   285.26 MB\n",
      "           8/10 tiles ( 80.0%) - Compressed:   326.18 MB\n",
      "           9/10 tiles ( 90.0%) - Compressed:   366.34 MB\n",
      "          10/10 tiles (100.0%) - Compressed:   407.27 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 407.27 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (10 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.40 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.00 MB  (tile metadata)\n",
      "Total compression size:          0.40 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       38.9201×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 10 tiles...\n",
      "           1/10 tiles ( 10.0%)\n",
      "           2/10 tiles ( 20.0%)\n",
      "           3/10 tiles ( 30.0%)\n",
      "           4/10 tiles ( 40.0%)\n",
      "           5/10 tiles ( 50.0%)\n",
      "           6/10 tiles ( 60.0%)\n",
      "           7/10 tiles ( 70.0%)\n",
      "           8/10 tiles ( 80.0%)\n",
      "           9/10 tiles ( 90.0%)\n",
      "          10/10 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.84614563\n",
      "Max Relative Error:   0.00995929\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    400 × 855 × 1215\n",
      "Total tiles:           10\n",
      "Compression ratio ρ:   38.9201×\n",
      "Space saved:           97.4%\n",
      "Error bound:           0.00995929 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 400   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f8f6f8-21d0-413b-95dd-eec3d1363cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         10 × 855 × 1215\n",
      "   Tiles per dim:     400 × 1 × 1\n",
      "   Total tiles:       400\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 400 tiles...\n",
      "           1/400 tiles (  0.2%) - Compressed:     1.07 MB\n",
      "          40/400 tiles ( 10.0%) - Compressed:    43.73 MB\n",
      "          80/400 tiles ( 20.0%) - Compressed:    87.41 MB\n",
      "         120/400 tiles ( 30.0%) - Compressed:   131.10 MB\n",
      "         160/400 tiles ( 40.0%) - Compressed:   174.84 MB\n",
      "         200/400 tiles ( 50.0%) - Compressed:   218.74 MB\n",
      "         240/400 tiles ( 60.0%) - Compressed:   262.35 MB\n",
      "         280/400 tiles ( 70.0%) - Compressed:   306.01 MB\n",
      "         320/400 tiles ( 80.0%) - Compressed:   349.78 MB\n",
      "         360/400 tiles ( 90.0%) - Compressed:   393.45 MB\n",
      "         400/400 tiles (100.0%) - Compressed:   437.07 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 437.07 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (400 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.43 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.01 MB  (tile metadata)\n",
      "Total compression size:          0.43 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       36.2663×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 400 tiles...\n",
      "           1/400 tiles (  0.2%)\n",
      "          40/400 tiles ( 10.0%)\n",
      "          80/400 tiles ( 20.0%)\n",
      "         120/400 tiles ( 30.0%)\n",
      "         160/400 tiles ( 40.0%)\n",
      "         200/400 tiles ( 50.0%)\n",
      "         240/400 tiles ( 60.0%)\n",
      "         280/400 tiles ( 70.0%)\n",
      "         320/400 tiles ( 80.0%)\n",
      "         360/400 tiles ( 90.0%)\n",
      "         400/400 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.84333801\n",
      "Max Relative Error:   0.00992624\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    10 × 855 × 1215\n",
      "Total tiles:           400\n",
      "Compression ratio ρ:   36.2663×\n",
      "Space saved:           97.2%\n",
      "Error bound:           0.00992624 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 10   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98df715e-0a06-4bd9-8292-245eaae1f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         1 × 855 × 1215\n",
      "   Tiles per dim:     4000 × 1 × 1\n",
      "   Total tiles:       4000\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%) - Compressed:     0.10 MB\n",
      "         400/4000 tiles ( 10.0%) - Compressed:    39.14 MB\n",
      "         800/4000 tiles ( 20.0%) - Compressed:    78.26 MB\n",
      "        1200/4000 tiles ( 30.0%) - Compressed:   117.33 MB\n",
      "        1600/4000 tiles ( 40.0%) - Compressed:   156.44 MB\n",
      "        2000/4000 tiles ( 50.0%) - Compressed:   195.55 MB\n",
      "        2400/4000 tiles ( 60.0%) - Compressed:   234.50 MB\n",
      "        2800/4000 tiles ( 70.0%) - Compressed:   273.50 MB\n",
      "        3200/4000 tiles ( 80.0%) - Compressed:   312.59 MB\n",
      "        3600/4000 tiles ( 90.0%) - Compressed:   351.69 MB\n",
      "        4000/4000 tiles (100.0%) - Compressed:   390.67 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 390.67 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (4000 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.38 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.03 MB  (tile metadata)\n",
      "Total compression size:          0.38 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       40.5712×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%)\n",
      "         400/4000 tiles ( 10.0%)\n",
      "         800/4000 tiles ( 20.0%)\n",
      "        1200/4000 tiles ( 30.0%)\n",
      "        1600/4000 tiles ( 40.0%)\n",
      "        2000/4000 tiles ( 50.0%)\n",
      "        2400/4000 tiles ( 60.0%)\n",
      "        2800/4000 tiles ( 70.0%)\n",
      "        3200/4000 tiles ( 80.0%)\n",
      "        3600/4000 tiles ( 90.0%)\n",
      "        4000/4000 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.82327271\n",
      "Max Relative Error:   0.00969007\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    1 × 855 × 1215\n",
      "Total tiles:           4000\n",
      "Compression ratio ρ:   40.5712×\n",
      "Space saved:           97.5%\n",
      "Error bound:           0.00969007 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 1   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7536e92c-72f0-48bf-bf92-04b3a7eddd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         1 × 855 × 1215\n",
      "   Tiles per dim:     4000 × 1 × 1\n",
      "   Total tiles:       4000\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%) - Compressed:     0.11 MB\n",
      "         400/4000 tiles ( 10.0%) - Compressed:    42.46 MB\n",
      "         800/4000 tiles ( 20.0%) - Compressed:    84.91 MB\n",
      "        1200/4000 tiles ( 30.0%) - Compressed:   127.29 MB\n",
      "        1600/4000 tiles ( 40.0%) - Compressed:   169.71 MB\n",
      "        2000/4000 tiles ( 50.0%) - Compressed:   212.12 MB\n",
      "        2400/4000 tiles ( 60.0%) - Compressed:   254.37 MB\n",
      "        2800/4000 tiles ( 70.0%) - Compressed:   296.68 MB\n",
      "        3200/4000 tiles ( 80.0%) - Compressed:   339.10 MB\n",
      "        3600/4000 tiles ( 90.0%) - Compressed:   381.51 MB\n",
      "        4000/4000 tiles (100.0%) - Compressed:   423.77 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 423.77 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (4000 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.41 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.03 MB  (tile metadata)\n",
      "Total compression size:          0.41 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       37.4022×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%)\n",
      "         400/4000 tiles ( 10.0%)\n",
      "         800/4000 tiles ( 20.0%)\n",
      "        1200/4000 tiles ( 30.0%)\n",
      "        1600/4000 tiles ( 40.0%)\n",
      "        2000/4000 tiles ( 50.0%)\n",
      "        2400/4000 tiles ( 60.0%)\n",
      "        2800/4000 tiles ( 70.0%)\n",
      "        3200/4000 tiles ( 80.0%)\n",
      "        3600/4000 tiles ( 90.0%)\n",
      "        4000/4000 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.82327271\n",
      "Max Relative Error:   0.00969007\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    1 × 855 × 1215\n",
      "Total tiles:           4000\n",
      "Compression ratio ρ:   37.4022×\n",
      "Space saved:           97.3%\n",
      "Error bound:           0.00969007 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 1   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    config.cmprAlgo = szAlgorithm.INTERP\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41d6e42-7afd-4b78-923e-2aab6b4f80d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         1 × 855 × 1215\n",
      "   Tiles per dim:     4000 × 1 × 1\n",
      "   Total tiles:       4000\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%) - Compressed:     0.11 MB\n",
      "         400/4000 tiles ( 10.0%) - Compressed:    43.94 MB\n",
      "         800/4000 tiles ( 20.0%) - Compressed:    87.84 MB\n",
      "        1200/4000 tiles ( 30.0%) - Compressed:   131.73 MB\n",
      "        1600/4000 tiles ( 40.0%) - Compressed:   175.62 MB\n",
      "        2000/4000 tiles ( 50.0%) - Compressed:   219.50 MB\n",
      "        2400/4000 tiles ( 60.0%) - Compressed:   263.26 MB\n",
      "        2800/4000 tiles ( 70.0%) - Compressed:   307.06 MB\n",
      "        3200/4000 tiles ( 80.0%) - Compressed:   350.93 MB\n",
      "        3600/4000 tiles ( 90.0%) - Compressed:   394.80 MB\n",
      "        4000/4000 tiles (100.0%) - Compressed:   438.54 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 438.54 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (4000 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.43 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.03 MB  (tile metadata)\n",
      "Total compression size:          0.43 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       36.1429×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 4000 tiles...\n",
      "           1/4000 tiles (  0.0%)\n",
      "         400/4000 tiles ( 10.0%)\n",
      "         800/4000 tiles ( 20.0%)\n",
      "        1200/4000 tiles ( 30.0%)\n",
      "        1600/4000 tiles ( 40.0%)\n",
      "        2000/4000 tiles ( 50.0%)\n",
      "        2400/4000 tiles ( 60.0%)\n",
      "        2800/4000 tiles ( 70.0%)\n",
      "        3200/4000 tiles ( 80.0%)\n",
      "        3600/4000 tiles ( 90.0%)\n",
      "        4000/4000 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.82327271\n",
      "Max Relative Error:   0.00969007\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    1 × 855 × 1215\n",
      "Total tiles:           4000\n",
      "Compression ratio ρ:   36.1429×\n",
      "Space saved:           97.2%\n",
      "Error bound:           0.00969007 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode, szAlgorithm\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 1   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    config.cmprAlgo = szAlgorithm.LORENZO_REG\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20bb6fc-7bf4-4cd5-87cb-bcc625c15a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSAL TILE-BASED COMPRESSION\n",
      "================================================================================\n",
      "\n",
      "📊 TILE CONFIGURATION\n",
      "   Data shape:        4000 × 855 × 1215\n",
      "   Tile size:         4000 × 855 × 1215\n",
      "   Tiles per dim:     1 × 1 × 1\n",
      "   Total tiles:       1\n",
      "   Compression mode:  ε = 0.01 (relative error bound)\n",
      "\n",
      "📂 Step 1: Loading original data...\n",
      "   ✅ Loaded: 4000 × 855 × 1215 elements\n",
      "   Size: 15.48 GB\n",
      "   Range: 84.96 (min: 225.59, max: 310.55)\n",
      "\n",
      "💾 Step 2: Storing original data in arrayD...\n",
      "   ✅ Original data stored\n",
      "\n",
      "🗜️  Step 3: Tile-based compression with SZ3...\n",
      "   Compressing 1 tiles...\n",
      "           1/1 tiles (100.0%) - Compressed:   398.55 MB\n",
      "   ✅ Compression complete!\n",
      "   Total compressed: 398.55 MB\n",
      "\n",
      "💾 Step 4: Storing compressed tiles in arrayG...\n",
      "   ✅ Compressed data stored\n",
      "\n",
      "💾 Step 5: Storing tile metadata (sizes)...\n",
      "   ✅ Tile metadata stored (1 tile sizes)\n",
      "\n",
      "📊 Step 6: Calculating compression ratio...\n",
      "--------------------------------------------------------------------------------\n",
      "Size of arrayD (disk):          15.48 GB\n",
      "Size of arrayG (disk):           0.39 GB  (compressed tiles)\n",
      "Size of arraySizes (disk):       0.00 MB  (tile metadata)\n",
      "Total compression size:          0.39 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🎯 Compression Ratio ρ:       39.7719×\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Step 7: Verifying decompression and error bounds...\n",
      "   Decompressing 1 tiles...\n",
      "           1/1 tiles (100.0%)\n",
      "\n",
      "Max Absolute Error:   0.84959412\n",
      "Max Relative Error:   0.00999987\n",
      "Target Epsilon:       0.01\n",
      "✅ SUCCESS: Error bound satisfied (Eq. 3)!\n",
      "\n",
      "================================================================================\n",
      "COMPRESSION SUMMARY\n",
      "================================================================================\n",
      "Tile configuration:    4000 × 855 × 1215\n",
      "Total tiles:           1\n",
      "Compression ratio ρ:   39.7719×\n",
      "Space saved:           97.5%\n",
      "Error bound:           0.00999987 ≤ 0.01\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "import os\n",
    "import shutil\n",
    "from pysz import sz, szConfig, szErrorBoundMode\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"Redsea_t2_4k_gan.dat\"\n",
    "ARRAY_D_NAME = \"arrayD\" \n",
    "ARRAY_G_NAME = \"arrayG\"\n",
    "ARRAY_SIZES_NAME = \"arraySizes\"\n",
    "\n",
    "SHAPE = (4000, 855, 1215)\n",
    "DTYPE = np.float32\n",
    "EPSILON = 1e-2\n",
    "\n",
    "# ============= CONFIGURABLE TILE SIZE =============\n",
    "# Change these to test different tiling strategies!\n",
    "TILE_T = 4000   # Full time dimension\n",
    "TILE_X = 855      # One X position\n",
    "TILE_Y = 1215   # Full Y dimension\n",
    "\n",
    "# Alternative configurations to try:\n",
    "# TILE_T, TILE_X, TILE_Y = 1, 855, 1215      # Original: 4000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 4000, 1, 1215     # This example: 855 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 10, 100, 100      # Small chunks: 468000 tiles\n",
    "# TILE_T, TILE_X, TILE_Y = 100, 100, 100     # Medium chunks\n",
    "# ===================================================\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"Calculate total size of folder including all subfolders\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def calculate_tile_grid(shape, tile_size):\n",
    "    \"\"\"Calculate how many tiles needed for each dimension\"\"\"\n",
    "    tiles_per_dim = []\n",
    "    total_tiles = 1\n",
    "    \n",
    "    for i, (dim_size, tile_dim) in enumerate(zip(shape, tile_size)):\n",
    "        num_tiles = math.ceil(dim_size / tile_dim)\n",
    "        tiles_per_dim.append(num_tiles)\n",
    "        total_tiles *= num_tiles\n",
    "    \n",
    "    return tiles_per_dim, total_tiles\n",
    "\n",
    "def extract_tile(data, tile_idx, shape, tile_size, tiles_per_dim):\n",
    "    \"\"\"Extract a specific tile from 3D data\"\"\"\n",
    "    # Convert flat index to 3D coordinates\n",
    "    idx_t = tile_idx // (tiles_per_dim[1] * tiles_per_dim[2])\n",
    "    idx_x = (tile_idx % (tiles_per_dim[1] * tiles_per_dim[2])) // tiles_per_dim[2]\n",
    "    idx_y = tile_idx % tiles_per_dim[2]\n",
    "    \n",
    "    # Calculate start and end positions\n",
    "    start_t = idx_t * tile_size[0]\n",
    "    end_t = min(start_t + tile_size[0], shape[0])\n",
    "    \n",
    "    start_x = idx_x * tile_size[1]\n",
    "    end_x = min(start_x + tile_size[1], shape[1])\n",
    "    \n",
    "    start_y = idx_y * tile_size[2]\n",
    "    end_y = min(start_y + tile_size[2], shape[2])\n",
    "    \n",
    "    # Extract tile\n",
    "    tile = data[start_t:end_t, start_x:end_x, start_y:end_y].copy()\n",
    "    \n",
    "    return tile, (start_t, end_t, start_x, end_x, start_y, end_y)\n",
    "\n",
    "def insert_tile(data, tile, coords):\n",
    "    \"\"\"Insert a decompressed tile back into data\"\"\"\n",
    "    start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "    data[start_t:end_t, start_x:end_x, start_y:end_y] = tile\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"UNIVERSAL TILE-BASED COMPRESSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # ============= CONFIGURATION INFO =============\n",
    "    tiles_per_dim, total_tiles = calculate_tile_grid(SHAPE, (TILE_T, TILE_X, TILE_Y))\n",
    "    \n",
    "    print(f\"📊 TILE CONFIGURATION\")\n",
    "    print(f\"   Data shape:        {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]}\")\n",
    "    print(f\"   Tile size:         {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"   Tiles per dim:     {tiles_per_dim[0]} × {tiles_per_dim[1]} × {tiles_per_dim[2]}\")\n",
    "    print(f\"   Total tiles:       {total_tiles}\")\n",
    "    print(f\"   Compression mode:  ε = {EPSILON} (relative error bound)\")\n",
    "    print()\n",
    "\n",
    "    # ============= LOAD ORIGINAL DATA =============\n",
    "    print(\"📂 Step 1: Loading original data...\")\n",
    "    try:\n",
    "        data_d = np.fromfile(INPUT_FILE, dtype=DTYPE).reshape(SHAPE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: {INPUT_FILE} not found!\")\n",
    "        return\n",
    "\n",
    "    d_max = data_d.max()\n",
    "    d_min = data_d.min()\n",
    "    v_range = d_max - d_min\n",
    "    \n",
    "    print(f\"   ✅ Loaded: {SHAPE[0]} × {SHAPE[1]} × {SHAPE[2]} elements\")\n",
    "    print(f\"   Size: {data_d.nbytes / (1024**3):.2f} GB\")\n",
    "    print(f\"   Range: {v_range:.2f} (min: {d_min:.2f}, max: {d_max:.2f})\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE ORIGINAL DATA IN TileDB =============\n",
    "    print(\"💾 Step 2: Storing original data in arrayD...\")\n",
    "    if os.path.exists(ARRAY_D_NAME):\n",
    "        shutil.rmtree(ARRAY_D_NAME)\n",
    "    \n",
    "    dom_d = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"time\", domain=(0, SHAPE[0]-1), tile=TILE_T, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"x\", domain=(0, SHAPE[1]-1), tile=TILE_X, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"y\", domain=(0, SHAPE[2]-1), tile=TILE_Y, dtype=np.int32)\n",
    "    )\n",
    "    schema_d = tiledb.ArraySchema(\n",
    "        domain=dom_d,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"temp\", dtype=DTYPE)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_D_NAME, schema_d)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_D_NAME, mode='w') as A:\n",
    "        A[:] = data_d\n",
    "    \n",
    "    print(f\"   ✅ Original data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= TILE-BASED COMPRESSION =============\n",
    "    print(f\"🗜️  Step 3: Tile-based compression with SZ3...\")\n",
    "    \n",
    "    config = szConfig()\n",
    "    config.errorBoundMode = szErrorBoundMode.REL\n",
    "    config.relErrorBound = EPSILON\n",
    "    \n",
    "    all_compressed_tiles = []\n",
    "    all_tile_sizes = []\n",
    "    total_compressed_size = 0\n",
    "    \n",
    "    print(f\"   Compressing {total_tiles} tiles...\")\n",
    "    \n",
    "    for tile_idx in range(total_tiles):\n",
    "        # Extract tile\n",
    "        tile_data, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        \n",
    "        # Compress tile\n",
    "        compressed_tile, _ = sz.compress(tile_data, config)\n",
    "        \n",
    "        all_compressed_tiles.append(compressed_tile)\n",
    "        tile_size = len(compressed_tile)\n",
    "        all_tile_sizes.append(tile_size)\n",
    "        total_compressed_size += tile_size\n",
    "        \n",
    "        # Progress indicator\n",
    "        progress_interval = max(1, total_tiles // 10)  # Show progress 10 times\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / total_tiles) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{total_tiles} tiles ({percentage:5.1f}%) - \"\n",
    "                  f\"Compressed: {total_compressed_size / (1024**2):8.2f} MB\")\n",
    "    \n",
    "    print(f\"   ✅ Compression complete!\")\n",
    "    print(f\"   Total compressed: {total_compressed_size / (1024**2):.2f} MB\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE COMPRESSED DATA IN TileDB =============\n",
    "    print(\"💾 Step 4: Storing compressed tiles in arrayG...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_G_NAME):\n",
    "        shutil.rmtree(ARRAY_G_NAME)\n",
    "    \n",
    "    # Concatenate all compressed tiles\n",
    "    concatenated_bytes = np.concatenate(all_compressed_tiles, axis=0)\n",
    "    \n",
    "    # Store in TileDB\n",
    "    dom_g = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"index\", domain=(0, len(concatenated_bytes)-1), \n",
    "                   tile=len(concatenated_bytes), dtype=np.int32)\n",
    "    )\n",
    "    schema_g = tiledb.ArraySchema(\n",
    "        domain=dom_g,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"bytes\", dtype=np.uint8)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_G_NAME, schema_g)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='w') as A:\n",
    "        A[:] = concatenated_bytes\n",
    "    \n",
    "    print(f\"   ✅ Compressed data stored\")\n",
    "    print()\n",
    "\n",
    "    # ============= STORE TILE SIZES METADATA =============\n",
    "    print(\"💾 Step 5: Storing tile metadata (sizes)...\")\n",
    "    \n",
    "    if os.path.exists(ARRAY_SIZES_NAME):\n",
    "        shutil.rmtree(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    tile_sizes_array = np.array(all_tile_sizes, dtype=np.int64)\n",
    "    \n",
    "    dom_sizes = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"tile_id\", domain=(0, len(tile_sizes_array)-1), \n",
    "                   tile=len(tile_sizes_array), dtype=np.int32)\n",
    "    )\n",
    "    schema_sizes = tiledb.ArraySchema(\n",
    "        domain=dom_sizes,\n",
    "        sparse=False,\n",
    "        attrs=[tiledb.Attr(name=\"size\", dtype=np.int64)]\n",
    "    )\n",
    "    tiledb.DenseArray.create(ARRAY_SIZES_NAME, schema_sizes)\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='w') as A:\n",
    "        A[:] = tile_sizes_array\n",
    "    \n",
    "    print(f\"   ✅ Tile metadata stored ({len(tile_sizes_array)} tile sizes)\")\n",
    "    print()\n",
    "\n",
    "    # ============= CALCULATE COMPRESSION RATIO =============\n",
    "    print(\"📊 Step 6: Calculating compression ratio...\")\n",
    "    \n",
    "    size_D_folder = get_folder_size(ARRAY_D_NAME)\n",
    "    size_G_folder = get_folder_size(ARRAY_G_NAME)\n",
    "    size_sizes_folder = get_folder_size(ARRAY_SIZES_NAME)\n",
    "    \n",
    "    total_stored_size = size_G_folder + size_sizes_folder\n",
    "    rho = size_D_folder / total_stored_size\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size of arrayD (disk):     {size_D_folder / (1024**3):10.2f} GB\")\n",
    "    print(f\"Size of arrayG (disk):     {size_G_folder / (1024**3):10.2f} GB  (compressed tiles)\")\n",
    "    print(f\"Size of arraySizes (disk): {size_sizes_folder / (1024**2):10.2f} MB  (tile metadata)\")\n",
    "    print(f\"Total compression size:    {total_stored_size / (1024**3):10.2f} GB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"🎯 Compression Ratio ρ:    {rho:10.4f}×\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    # ============= VERIFY ERROR BOUNDS =============\n",
    "    print(\"🔍 Step 7: Verifying decompression and error bounds...\")\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_G_NAME, mode='r') as A:\n",
    "        concatenated_read = A[:]['bytes']\n",
    "    \n",
    "    with tiledb.DenseArray(ARRAY_SIZES_NAME, mode='r') as A:\n",
    "        tile_sizes_read = A[:]['size']\n",
    "    \n",
    "    # Decompress all tiles and reconstruct\n",
    "    data_reconstructed = np.zeros(SHAPE, dtype=DTYPE)\n",
    "    byte_offset = 0\n",
    "    \n",
    "    print(f\"   Decompressing {len(tile_sizes_read)} tiles...\")\n",
    "    \n",
    "    for tile_idx, tile_size_val in enumerate(tile_sizes_read):\n",
    "        tile_size_val = int(tile_size_val)\n",
    "        compressed_tile_bytes = concatenated_read[byte_offset:byte_offset + tile_size_val]\n",
    "        byte_offset += tile_size_val\n",
    "        \n",
    "        # Get tile dimensions\n",
    "        _, coords = extract_tile(data_d, tile_idx, SHAPE, (TILE_T, TILE_X, TILE_Y), tiles_per_dim)\n",
    "        start_t, end_t, start_x, end_x, start_y, end_y = coords\n",
    "        tile_shape = (end_t - start_t, end_x - start_x, end_y - start_y)\n",
    "        \n",
    "        # Decompress\n",
    "        decompressed_tile, _ = sz.decompress(compressed_tile_bytes, DTYPE, tile_shape)\n",
    "        \n",
    "        # Insert back\n",
    "        insert_tile(data_reconstructed, decompressed_tile, coords)\n",
    "        \n",
    "        progress_interval = max(1, len(tile_sizes_read) // 10)\n",
    "        if (tile_idx + 1) % progress_interval == 0 or tile_idx == 0:\n",
    "            percentage = ((tile_idx + 1) / len(tile_sizes_read)) * 100\n",
    "            print(f\"      {tile_idx + 1:6d}/{len(tile_sizes_read)} tiles ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Verify error bounds\n",
    "    diff = np.abs(data_d - data_reconstructed)\n",
    "    max_pointwise_diff = diff.max()\n",
    "    actual_max_rel_error = max_pointwise_diff / v_range\n",
    "    \n",
    "    print()\n",
    "    print(f\"Max Absolute Error:   {max_pointwise_diff:.8f}\")\n",
    "    print(f\"Max Relative Error:   {actual_max_rel_error:.8f}\")\n",
    "    print(f\"Target Epsilon:       {EPSILON}\")\n",
    "    \n",
    "    if actual_max_rel_error <= EPSILON + 1e-9:\n",
    "        print(\"✅ SUCCESS: Error bound satisfied (Eq. 3)!\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Error bound NOT satisfied!\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPRESSION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Tile configuration:    {TILE_T} × {TILE_X} × {TILE_Y}\")\n",
    "    print(f\"Total tiles:           {total_tiles}\")\n",
    "    print(f\"Compression ratio ρ:   {rho:.4f}×\")\n",
    "    print(f\"Space saved:           {((size_D_folder - total_stored_size) / size_D_folder * 100):.1f}%\")\n",
    "    print(f\"Error bound:           {actual_max_rel_error:.8f} ≤ {EPSILON}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ef1d3-d27c-4171-ba8f-5a026d6c587f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
